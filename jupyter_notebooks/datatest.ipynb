{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\minorProject\\WDSS\\jupyter_notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Display current working directory\n",
    "print(os.getcwd())\n",
    "# To make sure opencv imports .exr files\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\minorProject\\WDSS\n"
     ]
    }
   ],
   "source": [
    "# Set working directory to one level up\n",
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from config import device\n",
    "import config\n",
    "import os\n",
    "import numpy as np\n",
    "from utils.image_utils import ImageUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from enum import Enum\n",
    "\n",
    "class GBufferType(Enum):\n",
    "    \"\"\"Enum class for GBuffer types.\"\"\"\n",
    "    BASE_COLOR = 0\n",
    "    BASE_COLOR_AA = 1\n",
    "    METALLIC = 2\n",
    "    MOTION_VECTOR = 3\n",
    "    NOV = 4\n",
    "    POST_TONEMAP_HDR_COLOR = 5\n",
    "    SCENE_DEPTH = 6\n",
    "    WORLD_NORMAL = 7\n",
    "\n",
    "class WDSSdataset(Dataset):\n",
    "    \"Dataset class for the WDSS dataset.\"\n",
    "    def __init__(self, settings):\n",
    "        self.settings = settings\n",
    "        self.data = []\n",
    "        self.high_res_path = self._get_file_paths('high_res')\n",
    "        self.low_res_path = self._get_file_paths('low_res')\n",
    "        self.all_g_buffer_path = self._get_file_paths('g_buffers')\n",
    "        self.buffer_paths = self._group_g_buffers(60)\n",
    "\n",
    "        print(f\"Found {len(self.high_res_path)} high res images\")\n",
    "        print(f\"Found {len(self.low_res_path)} low res images\")\n",
    "        print(f\"Found {len(self.buffer_paths)} g buffer groups\")\n",
    "\n",
    "    def _get_file_paths(self, subfolder):\n",
    "        \"\"\"Retrieve file paths from a specific subfolder.\"\"\"\n",
    "        folder_path = os.path.join(self.settings.dataset_path, subfolder)\n",
    "        return [os.path.join(folder_path, f) for f in os.listdir(folder_path)]\n",
    "\n",
    "    def _group_g_buffers(self, group_size):\n",
    "        \"\"\"Group g_buffers into lists of specified group size.\"\"\"\n",
    "        buffer_groups = []\n",
    "        num_groups = len(self.all_g_buffer_path) // group_size\n",
    "        for i in range(group_size):\n",
    "            buffer = [\n",
    "                self.all_g_buffer_path[j] for j in range(i, len(self.all_g_buffer_path), group_size)\n",
    "            ]\n",
    "            buffer_groups.append(buffer)\n",
    "        return buffer_groups\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.high_res_path)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load high-resolution and low-resolution images\n",
    "        high_res = ImageUtils.load_exr_image_opencv(self.high_res_path[idx])\n",
    "        low_res = ImageUtils.load_exr_image_opencv(self.low_res_path[idx])\n",
    "                    \n",
    "        # Permute dimensions to CHW (if the loaded images are in HWC format)\n",
    "        high_res = high_res.transpose(2, 0, 1)  # HWC -> CHW\n",
    "        low_res = low_res.transpose(2, 0, 1)    # HWC -> CHW\n",
    "\n",
    "        # Load g_buffers and permute dimensions to CHW\n",
    "        g_buffers = {\n",
    "            g_buffer.name.lower(): ImageUtils.load_exr_image_opencv(self.buffer_paths[idx][g_buffer.value]).transpose(2, 0, 1)\n",
    "            for g_buffer in GBufferType\n",
    "        }\n",
    "        \n",
    "        # Create a sample dictionary\n",
    "        sample = {\n",
    "            'high_res': high_res,\n",
    "            'low_res': low_res,\n",
    "            'g_buffers': g_buffers\n",
    "        }\n",
    "        \n",
    "        return sample\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 high res images\n",
      "Found 61 low res images\n",
      "Found 60 g buffer groups\n"
     ]
    }
   ],
   "source": [
    "setting = config.Settings()\n",
    "dataset = WDSSdataset(settings=setting)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "High-res: torch.Size([10, 3, 720, 1280])\n",
      "Low-res: torch.Size([10, 3, 360, 640])\n",
      "base_color:  torch.Size([10, 3, 576, 1024])\n",
      "base_color_aa:  torch.Size([10, 3, 576, 1024])\n",
      "metallic:  torch.Size([10, 3, 576, 1024])\n",
      "motion_vector:  torch.Size([10, 3, 576, 1024])\n",
      "nov:  torch.Size([10, 3, 576, 1024])\n",
      "post_tonemap_hdr_color:  torch.Size([10, 3, 576, 1024])\n",
      "scene_depth:  torch.Size([10, 3, 576, 1024])\n",
      "world_normal:  torch.Size([10, 3, 576, 1024])\n"
     ]
    }
   ],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(f\"Batch {i_batch}\")\n",
    "    print(f\"High-res: {sample_batched['high_res'].size()}\")\n",
    "    # Print the size of the first low-resolution image in the batch\n",
    "    print(f\"Low-res: {sample_batched['low_res'].size()}\")\n",
    "    # Print the size of the first g-buffer in the batch\n",
    "    for key, value in sample_batched['g_buffers'].items():\n",
    "        # Proper Padding\n",
    "        print(f\"{key}:  {value.size()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wdss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
